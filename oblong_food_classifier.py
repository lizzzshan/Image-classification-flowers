# -*- coding: utf-8 -*-
"""oblong-food-classifier

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-XIUonnL7kH8ZIoFzVFFV97xPVk6gCKK

# Training an oblong food classifier

Do you ever worry about being unable to identify the difference between a spring roll, hot dog, and churro? Me neither, but let's pretend that did happen. You don't need to fear any longer because this model will try its best to tell you what it is! 

**NOTE**: Running this will take up some time! I highly reccomend running on GPU. You can change to GPU by selecting `Runtime > Change runtime type > Hardware accelerator > GPU`

### Loading and preparing the data
"""

import torch
# Import PyTorch and nn 
import torch
from torch import nn

# Make device agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"
device

!pip install -Uqq fastai 
from fastai.vision.all import *

# Downloading the flowers dataset: https://docs.fast.ai/data.external.html
food_path = untar_data(URLs.FOOD)

# Display table using Pandas to look at the categories
pd.read_json('/root/.fastai/data/food-101/test.json')

# Set the labels as the foods we want to classify 
hot_dog = 'hot_dog'
spring_rolls = 'spring_rolls'
churros = 'churros'

"""### Data prep and some cleaning up

This function has 2 main roles:

1.   Remove all the images that don't have *hot dog*, *churro*, or *spring rolls*. 
2.   Rename sashimi or spring roll images to have that in their filename for easier usage.


"""

for img in get_image_files(food_path):
  # rename the correct images to have the label name 
  if hot_dog in str(img):
    img.rename(f"{img.parent}/{hot_dog}-{img.name}")
  elif spring_rolls in str(img):
    img.rename(f"{img.parent}/{spring_rolls}-{img.name}")
  # If the images don't fit in those categories, remove img
  elif churros in str(img):
    img.rename(f"{img.parent}/{churros}-{img.name}")
  else:
    os.remove(img)

"""# Training the model"""

def getLabel(fileName):
  return fileName.split('-')[0]

# Testing getLabel function 
# ---------------------------

# getLabel("sashimi-100113.jpg")
#getLabel("spring_rolls-100113.jpg")

dls = ImageDataLoaders.from_name_func(
    food_path, get_image_files(food_path), valid_pct=0.2, seed=420,
    label_func=getLabel, item_tfms=Resize(32))

dls.train.show_batch()

"""# Convolutional neural network"""

learn = cnn_learner(dls, resnet34, metrics=error_rate, pretrained=True)
learn.fine_tune(epochs=1)

"""# Verify model

### Test the model using uploaded images
"""

from google.colab import files
input_img = files.upload()

for img in input_img.items():
  uploaded_img = img[0]
img = PILImage.create(uploaded_img)
img.show()

label,_,probs = learn.predict(img)

print(f"This is most likely {label}.")

"""# Find the accuracy using confusion matrix
[More about this here](https://deepchecks.com/how-to-check-the-accuracy-of-your-machine-learning-model/#:~:text=Accuracy%20score%20in%20machine%20learning%20is%20an%20evaluation%20metric%20that,the%20total%20number%20of%20predictions.)

How to improve ML model accuracy:
TODO: do your research
1.   List item
2.   List item


"""

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix()
interp.plot_top_losses(6)

"""### Next steps

I plan to deploy this using Docker for easier audience usage.

### Deploy
"""

# Export model as .pkl file
learn.export()

model_path = get_files(food_path, '.pkl')[0]
model_path

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

learn_inf = load_learner(model_path)
learn_inf.predict(mpimg.imread(get_image_files(food_path)[0])) #raw prediction

# Get labels
learn_inf.dls.vocab

from google.colab import files
files.download(model_path)

